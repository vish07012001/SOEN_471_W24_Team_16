Data Preprocessing
    1. Loading the Data
    2. Concatenating Dataframes
    3. Remove unnecessary columns: Clean up any outliers that may appear in our data files that are not part of the data we want. 
    4. Handling Null Values:
        * Categorical features were handled by introducing a new category 'missing' using SimpleImputer with the 'constant' strategy, which fills missing values with the value 'missing'.
        * Numerical feature 'CWE' was handled by imputing missing values with a constant value of 0 using SimpleImputer.
    5. Encoding Categorical Features: Since machine learning algorithms typically require numerical input, categorical features like Severity, Description, Tool Category, Tool Name, and Rule Name were encoded into numerical format. One-hot encoding was employed for this purpose, it abstracts away the details of creating dummy variables and concatenating these dummy variable columns with the original DataFrame to produce the final one-hot encoded DataFrame.

Hyperparameters Tuning
    Grid Search and Random Search were used for Hyperparameters Tuning for both Decision Tree and Random Forest. 
    1. Grid Search: 
        - Decision Tree: This exhaustive search over specified parameter values for the Decision Tree model aimed to identify the combination of parameters that could maximize the model's accuracy. 
            - Best parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}
            - Best score: 0.9587343423799582
        - Random Forest: Leveraging the same systematic approach as with the Decision Tree, we applied Grid Search to the Random Forest Classifier. Given the complexity and the inherently higher number of hyperparameters in Random Forest models, this stage was crucial in dissecting and understanding the influence of each hyperparameter on the ensemble's performance.
            - Best parameters: {'bootstrap': False, 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100}
            - Best score: 0.9620694154488518

    2. Random Search:
        - Decision Tree: This method samples a subset of hyperparameters from a defined distribution, offering a faster, yet still effective, approach to identifying optimal parameters.
            - Best parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 4}
            - Best score: 0.9587343423799582
        - Random Forest: Efficiently navigating the extensive hyperparameter landscape of the Random Forest, and took less time than grid search 
            - Best parameters: {'bootstrap': False, 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 195}
            - Best score: 0.9616527487821852
    
    We decided to use these hyperparameters on a training set that is 50% of the dataset:
    * Decision Tree: {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}
    * Random Forest: {'bootstrap': False, 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 195}
        
Model Evaluation
    * Upon fine-tuning the models, the evaluation results did not improve aggressively. The default settings of the hyperparameters result in a model that is not too simple or too complex. In other words, the default hyperparameters strike a good balance between capturing the underlying patterns in the data and avoiding overfitting while achieving good results.
    * Surprisingly, the Random Forest Classifier, even with default hyperparameters, did not outperform the Decision Tree Classifier as anticipated. Both classifiers achieve similar performance metrics, indicating that in this particular dataset and task, the ensemble approach of Random Forest did not offer significant advantages over the single Decision Tree model.
    * Both models achieved relatively good precision and recall results, suggesting both are good at capturing true positives while minimizing false positives.
    * Overall, the results suggest that the default hyperparameters of both models work well for this dataset. Fine-tuning the hyperparameters did not lead to substantial improvements in performance, indicating that the default settings already capture the underlying patterns in the data effectively.
